---
phase: 13-pipeline-integration
plan: 01
type: execute
wave: 1
depends_on: []
files_modified:
  - ~/Library/Mobile Documents/iCloud~md~obsidian/Documents/model-citizen-vault/scripts/normalize-url.py
  - ~/Library/Mobile Documents/iCloud~md~obsidian/Documents/model-citizen-vault/scripts/dedup-check.py
  - ~/Library/Mobile Documents/iCloud~md~obsidian/Documents/model-citizen-vault/scripts/migrate-normalize-urls.py
autonomous: true
requirements: [INTG-02]

must_haves:
  truths:
    - "normalize-url.py strips UTM params, share_id, fbclid, gclid and www. prefix from URLs, producing identical canonical URLs for the same article regardless of sharing source"
    - "dedup-check.py finds an existing vault note when given a URL that matches after normalization, and returns None when no match exists"
    - "migrate-normalize-urls.py adds normalized_url field to all existing vault source notes without creating duplicates or corrupting frontmatter"
  artifacts:
    - path: "~/Library/Mobile Documents/iCloud~md~obsidian/Documents/model-citizen-vault/scripts/normalize-url.py"
      provides: "URL normalization function — strip tracking params, www., trailing slashes, sort query params"
    - path: "~/Library/Mobile Documents/iCloud~md~obsidian/Documents/model-citizen-vault/scripts/dedup-check.py"
      provides: "Dedup check — find existing note by normalized URL, merge tags on duplicate, update source to array"
    - path: "~/Library/Mobile Documents/iCloud~md~obsidian/Documents/model-citizen-vault/scripts/migrate-normalize-urls.py"
      provides: "One-time migration — add normalized_url to all existing source notes"
  key_links:
    - from: "dedup-check.py"
      to: "normalize-url.py"
      via: "import normalize_url function"
      pattern: "from normalize_url import"
    - from: "dedup-check.py"
      to: "vault sources/**/*.md"
      via: "glob scan of source_url frontmatter fields"
      pattern: "glob.*sources.*\\.md"
    - from: "migrate-normalize-urls.py"
      to: "normalize-url.py"
      via: "import normalize_url function"
      pattern: "from normalize_url import"
---

<objective>
Create the URL normalization utility, dedup checker, and retroactive migration script. These are the foundation for cross-source deduplication — ensuring the same article captured via Slack, Outlook, web capture, and GoodLinks produces only one vault note.

Purpose: INTG-02 requires URL normalization to prevent duplicates across all sources. This plan builds the shared infrastructure; Plan 02 wires it into the daily automation.

Output: Three Python scripts in the vault scripts directory — normalize-url.py (shared utility), dedup-check.py (dedup logic with tag merge), migrate-normalize-urls.py (one-time migration for existing notes).
</objective>

<execution_context>
@/Users/adial/.claude/get-shit-done/workflows/execute-plan.md
@/Users/adial/.claude/get-shit-done/templates/summary.md
</execution_context>

<context>
@.planning/PROJECT.md
@.planning/ROADMAP.md
@.planning/STATE.md
@.planning/phases/13-pipeline-integration/13-RESEARCH.md
@.planning/phases/13-pipeline-integration/13-CONTEXT.md
@~/Library/Mobile Documents/iCloud~md~obsidian/Documents/model-citizen-vault/scripts/goodlinks-query.py
@~/Library/Mobile Documents/iCloud~md~obsidian/Documents/model-citizen-vault/scripts/update-frontmatter.py
</context>

<tasks>

<task type="auto">
  <name>Task 1: Create normalize-url.py and dedup-check.py</name>
  <files>~/Library/Mobile Documents/iCloud~md~obsidian/Documents/model-citizen-vault/scripts/normalize-url.py, ~/Library/Mobile Documents/iCloud~md~obsidian/Documents/model-citizen-vault/scripts/dedup-check.py</files>
  <action>
Create two Python scripts in the vault scripts directory:

**normalize-url.py** — Shared URL normalization utility:

1. `normalize_url(url: str) -> str` function:
   - Parse with `urllib.parse.urlparse`
   - Lowercase scheme and hostname
   - Strip `www.` prefix from hostname
   - Remove fragment (hash)
   - Strip trailing slash from path (but preserve root `/`)
   - Remove tracking params from query string. Strip list:
     ```
     utm_source, utm_medium, utm_campaign, utm_content, utm_term,
     share_id, fbclid, gclid, mc_cid, mc_eid, mkt_tok, trk, trkCampaign,
     ref, _hsenc, _hsmi, ck_subscriber_id
     ```
   - Sort remaining query params alphabetically
   - Reconstruct URL with `urlunparse` using `https` scheme always
   - Return canonical URL string

2. CLI mode: `python3 normalize-url.py "https://example.com?utm_source=foo"` prints normalized URL. Useful for testing.

3. Shebang: `#!/usr/bin/env /opt/homebrew/bin/python3.12`

**dedup-check.py** — Dedup check with tag merge:

1. `find_existing_note(normalized_url: str, sources_dir: str) -> str | None` — Scans all `.md` files in sources_dir (recursive) looking for `source_url:` frontmatter that normalizes to the same URL. Returns file path if found, None otherwise.

2. `merge_tags_and_source(existing_file: str, new_tags: list[str], new_source: str)` — Opens existing note, reads its frontmatter:
   - If `source` is a string, convert to `sources: [old_source, new_source]` array (keeping `source` field as-is for backward compat, adding `sources` plural field)
   - Union new_tags into existing `tags` array (no duplicates)
   - Write updated frontmatter back using the same pattern as `update-frontmatter.py` (read file, find `---` boundaries, update YAML, write back)

3. `check_and_handle_dedup(url: str, sources_dir: str, new_tags: list[str], new_source: str, dry_run: bool = False) -> bool` — Main entry point:
   - Normalize the URL
   - Call find_existing_note
   - If found: merge tags and source (unless dry_run), print "DEDUP: {url} matches {existing_file}", return True
   - If not found: return False

4. CLI mode: `python3 dedup-check.py --url "https://..." --sources-dir /path/to/sources [--dry-run]`

5. Shebang: `#!/usr/bin/env /opt/homebrew/bin/python3.12`

Both scripts must use `encoding='utf-8'` for all file I/O.
  </action>
  <verify>
1. Test normalize-url.py:
   - `/opt/homebrew/bin/python3.12 normalize-url.py "https://www.reddit.com/r/ClaudeAI/comments/1r3hr40/?share_id=MbKVTkskptGAS6c8Tc0NO&utm_content=1&utm_medium=ios_app"` should output `https://reddit.com/r/ClaudeAI/comments/1r3hr40` (no www, no tracking params, no trailing slash)
   - `/opt/homebrew/bin/python3.12 normalize-url.py "https://example.com"` should output `https://example.com` (unchanged)

2. Test dedup-check.py:
   - `/opt/homebrew/bin/python3.12 dedup-check.py --url "https://example.com/test" --sources-dir /tmp/dedup-test --dry-run` should report no match (empty dir)
  </verify>
  <done>normalize-url.py correctly strips tracking params and www prefix; dedup-check.py finds existing notes by normalized URL and can merge tags/source on duplicates</done>
</task>

<task type="auto">
  <name>Task 2: Create migrate-normalize-urls.py and run retroactive migration</name>
  <files>~/Library/Mobile Documents/iCloud~md~obsidian/Documents/model-citizen-vault/scripts/migrate-normalize-urls.py</files>
  <action>
Create a one-time migration script that adds `normalized_url` to all existing vault source notes:

1. Scan all `.md` files in `~/Library/Mobile Documents/iCloud~md~obsidian/Documents/model-citizen-vault/sources/` recursively
2. For each file with `source_url:` in frontmatter:
   - Extract the source_url value
   - Run it through `normalize_url()` (imported from normalize-url.py)
   - Add `normalized_url: "{value}"` to the frontmatter (after source_url line)
   - Skip if `normalized_url` already present
3. Print summary: "Migrated X notes, Y already had normalized_url, Z had no source_url"
4. Support `--dry-run` flag
5. Shebang: `#!/usr/bin/env /opt/homebrew/bin/python3.12`

After creating the script, run it:
- First with `--dry-run` to verify counts
- Then for real to apply migration

Verify: spot-check 3 migrated files to confirm `normalized_url` field is present and correctly normalized.
  </action>
  <verify>
1. `--dry-run` reports count of files to migrate
2. Real run adds `normalized_url` to source notes
3. `grep -r "normalized_url:" ~/Library/Mobile\ Documents/iCloud~md~obsidian/Documents/model-citizen-vault/sources/ | wc -l` shows count matching migrated files
4. Spot-check: `head -15` of 3 random migrated files shows correct normalized_url
  </verify>
  <done>All existing vault source notes have normalized_url field in frontmatter; migration script is idempotent (re-running adds 0 new fields)</done>
</task>

</tasks>

<verification>
1. `normalize-url.py` exists, is executable, and strips tracking params from Reddit iOS URLs
2. `dedup-check.py` exists, is executable, and can find/merge duplicate notes
3. `migrate-normalize-urls.py` exists and has been run successfully
4. All existing vault source notes have `normalized_url` in frontmatter
5. Re-running migration produces 0 changes (idempotent)
</verification>

<success_criteria>
- normalize-url.py produces identical canonical URLs for the same article regardless of UTM/sharing params
- dedup-check.py correctly identifies when a URL already exists in the vault and merges tags without creating duplicates
- All existing source notes (YouTube, test, GoodLinks) have normalized_url field after migration
</success_criteria>

<output>
After completion, create `.planning/phases/13-pipeline-integration/13-01-SUMMARY.md`
</output>
