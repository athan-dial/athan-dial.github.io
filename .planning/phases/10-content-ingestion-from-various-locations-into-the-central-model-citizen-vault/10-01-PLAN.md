---
phase: 10-content-ingestion
plan: 01
type: execute
wave: 1
depends_on: []
files_modified:
  - ~/model-citizen-vault/ingest/shared/queue.js
  - ~/model-citizen-vault/ingest/shared/dedup.js
  - ~/model-citizen-vault/ingest/shared/normalize.js
  - ~/model-citizen-vault/ingest/shared/vault-writer.js
  - ~/model-citizen-vault/ingest/config.js
  - ~/model-citizen-vault/ingest/sources/web-capture.js
  - ~/model-citizen-vault/ingest/package.json
  - ~/model-citizen-vault/ingest/.env.example
autonomous: true

must_haves:
  truths:
    - "User can capture a web URL via CLI and it appears as a queue JSON file"
    - "User can process the queue and a normalized markdown note appears in the vault sources folder"
    - "Capturing the same URL twice merges provenance instead of creating a duplicate"
    - "Extracted article contains full text content, not just a URL stub"
  artifacts:
    - path: "~/model-citizen-vault/ingest/shared/queue.js"
      provides: "Queue read/write operations for .queue/ directory"
      exports: ["addToQueue", "readQueue", "markProcessed"]
    - path: "~/model-citizen-vault/ingest/shared/dedup.js"
      provides: "URL normalization, hashing, and existing note lookup"
      exports: ["normalizeURL", "urlHash", "findExistingNote"]
    - path: "~/model-citizen-vault/ingest/shared/normalize.js"
      provides: "Markdown note creation with consistent frontmatter"
      exports: ["createMarkdownNote"]
    - path: "~/model-citizen-vault/ingest/shared/vault-writer.js"
      provides: "Write-to-vault with dedup check and provenance merge"
      exports: ["writeToVault"]
    - path: "~/model-citizen-vault/ingest/sources/web-capture.js"
      provides: "Readability-based article extraction and queue capture"
      exports: ["captureURL", "extractArticle"]
    - path: "~/model-citizen-vault/ingest/package.json"
      provides: "Node.js project with all dependencies"
  key_links:
    - from: "sources/web-capture.js"
      to: "shared/vault-writer.js"
      via: "writeToVault call after extraction"
      pattern: "writeToVault\\("
    - from: "shared/vault-writer.js"
      to: "shared/dedup.js"
      via: "findExistingNote before writing"
      pattern: "findExistingNote\\("
    - from: "shared/normalize.js"
      to: "vault frontmatter"
      via: "source_type field in frontmatter"
      pattern: "source_type:"
---

<objective>
Build the shared ingestion infrastructure (queue, dedup, normalization, vault writing) and the web article capture source.

Purpose: All subsequent source connectors (Slack, Outlook) depend on these shared modules. Web capture is the simplest source and validates the entire pipeline end-to-end.

Output: Working Node.js project at ~/model-citizen-vault/ingest/ with queue-based capture, Readability-based article extraction, dedup by URL hash, and normalized vault notes with source_type frontmatter.
</objective>

<execution_context>
@/Users/adial/.claude/get-shit-done/workflows/execute-plan.md
@/Users/adial/.claude/get-shit-done/templates/summary.md
</execution_context>

<context>
@.planning/PROJECT.md
@.planning/ROADMAP.md
@.planning/STATE.md
@.planning/phases/10-content-ingestion-from-various-locations-into-the-central-model-citizen-vault/10-RESEARCH.md
@.planning/phases/05-youtube-ingestion/05-01-SUMMARY.md
@.planning/phases/07-enrichment-pipeline/07-01-SUMMARY.md
</context>

<tasks>

<task type="auto">
  <name>Task 1: Scaffold ingest project with shared modules</name>
  <files>
    ~/model-citizen-vault/ingest/package.json
    ~/model-citizen-vault/ingest/config.js
    ~/model-citizen-vault/ingest/.env.example
    ~/model-citizen-vault/ingest/shared/queue.js
    ~/model-citizen-vault/ingest/shared/dedup.js
    ~/model-citizen-vault/ingest/shared/normalize.js
    ~/model-citizen-vault/ingest/shared/vault-writer.js
    ~/model-citizen-vault/ingest/.queue/.gitkeep
  </files>
  <action>
    Create Node.js project at ~/model-citizen-vault/ingest/ with "type": "module" in package.json.

    Install dependencies: @mozilla/readability jsdom turndown gray-matter dotenv glob

    config.js: Load dotenv, export VAULT_PATH (default ~/model-citizen-vault), QUEUE_DIR (VAULT_PATH/ingest/.queue), SOURCES_DIR (VAULT_PATH/sources). Include placeholders for SLACK_BOT_TOKEN, SLACK_BOSS_DM_ID, MS_CLIENT_ID, MS_TENANT_ID, MS_CLIENT_SECRET, BOSS_EMAIL from .env.

    .env.example: List all env vars with placeholder comments.

    shared/queue.js:
    - addToQueue(type, data): Write JSON file to .queue/ with {type, url, note, timestamp, processed: false}. Filename: {type}-{Date.now()}.json
    - readQueue(): Read all unprocessed .json files from .queue/, return parsed array
    - markProcessed(filename): Delete the queue file after processing

    shared/dedup.js:
    - normalizeURL(url): Strip fragments, utm_* params, fbclid, gclid, mc_cid, mc_eid; normalize to https; sort query params; lowercase
    - urlHash(url): SHA-256 of normalizeURL, first 16 hex chars
    - findExistingNote(vaultSourcesDir, url): Glob all .md files in sources/, parse frontmatter with gray-matter, return first match where url_hash matches. Return {file, frontmatter} or null.

    shared/normalize.js:
    - createMarkdownNote(content, metadata): Use gray-matter stringify. Frontmatter: title, url, url_hash (from dedup.urlHash), source_type (article|youtube|slack|email), captured_at (ISO), provenance (string or array), status: "captured", note (optional context). Body: the extracted text content.

    shared/vault-writer.js:
    - writeToVault(content, metadata, vaultSourcesDir): Call findExistingNote. If exists: read file, append to provenance array (e.g., "also shared via {metadata.sourceType}"), rewrite file. If not exists: call createMarkdownNote, write to vaultSourcesDir/{slug-from-title}.md with sanitized filename.

    Create .queue/ directory with .gitkeep.
  </action>
  <verify>
    cd ~/model-citizen-vault/ingest && node -e "import('./shared/queue.js')" && node -e "import('./shared/dedup.js')" && node -e "import('./shared/normalize.js')" && node -e "import('./shared/vault-writer.js')"
  </verify>
  <done>All shared modules import without errors. package.json has all dependencies. .queue/ directory exists.</done>
</task>

<task type="auto">
  <name>Task 2: Web article capture with Readability + CLI interface</name>
  <files>
    ~/model-citizen-vault/ingest/sources/web-capture.js
  </files>
  <action>
    Create sources/web-capture.js with two modes:

    1. Queue mode (--queue flag): Takes --url and optional --note, writes to .queue/ via shared/queue.js. Fast, no network calls. This is what the share sheet will invoke.

    2. Process mode (default when called from scan orchestrator): Takes a queue item, fetches the URL HTML via fetch(), extracts article with @mozilla/readability + jsdom (see research Pattern 5 for JSDOM reuse to avoid memory leaks), converts HTML content to markdown with turndown, then calls vault-writer.writeToVault with source_type: "article".

    CLI interface using process.argv parsing (no commander dependency needed):
    - node web-capture.js --queue --url "https://..." --note "boss recommended"
    - node web-capture.js --process (reads from queue, processes all web-type items)

    Handle Readability returning null (paywalled content): Log warning, create note with just URL and title "Could not extract — paywalled or blocked", set status: "capture_failed".

    Clean unwanted HTML elements before Readability: script, style, noscript, iframe, .advertisement, .sidebar, nav (per research example).

    Test end-to-end: Queue a URL, process it, verify vault note created with correct frontmatter (title, url, url_hash, source_type: article, captured_at, status: captured) and markdown body.
  </action>
  <verify>
    cd ~/model-citizen-vault/ingest && node sources/web-capture.js --queue --url "https://example.com" --note "test" && ls .queue/web-*.json && node sources/web-capture.js --process && ls ~/model-citizen-vault/sources/*.md
  </verify>
  <done>Queuing a URL creates a .queue/web-*.json file. Processing the queue fetches the article, extracts text via Readability, and writes a markdown note to ~/model-citizen-vault/sources/ with correct frontmatter including url_hash and source_type: article. Re-processing the same URL merges provenance instead of duplicating.</done>
</task>

</tasks>

<verification>
1. Run `node sources/web-capture.js --queue --url "https://example.com" --note "test capture"` — queue file created
2. Run `node sources/web-capture.js --process` — vault note created in sources/
3. Inspect vault note: has title, url, url_hash, source_type: article, captured_at, status: captured, note: "test capture"
4. Run same URL again with different note — provenance merged, no duplicate file
5. All shared modules can be imported independently
</verification>

<success_criteria>
- Shared infrastructure (queue, dedup, normalize, vault-writer) fully functional
- Web article capture works end-to-end: queue → fetch → extract → vault note
- Deduplication correctly merges provenance for same-URL captures
- Frontmatter follows schema with source_type field
- Node.js project with all dependencies installed
</success_criteria>

<output>
After completion, create `.planning/phases/10-content-ingestion-from-various-locations-into-the-central-model-citizen-vault/10-01-SUMMARY.md`
</output>
